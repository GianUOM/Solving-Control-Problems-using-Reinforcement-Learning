{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-mxQQH_0ROz",
        "outputId": "b62deb97-1330-4494-bb5b-8dbb5df91205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: swig in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install swig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xESaDkB81ap7",
        "outputId": "621e824d-48d0-41a2-939c-c23a80d79546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IThPMRuH4rzq",
        "outputId": "2f725b0f-a1be-487c-e6e8-19508012222a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium[box2d] in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in c:\\users\\giann\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium[box2d]) (4.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFc6fvxb84C_"
      },
      "source": [
        "## 1. Apply standard DQN. Decide on the design choices in your code (e.g., network architecture) and perform hyperparameter tuning on at least two parameters of your models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Sequence\n",
        "from collections import namedtuple, deque\n",
        "import itertools\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7P3F4BprU4Hg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with learning_rate=0.0005, hidden_size=64\n",
            "Episode: 50 Avg Results: -186.84 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -184.86 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -122.89 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -102.71 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -132.10 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: -120.16 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: -79.88 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: -23.48 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: 46.27 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: 139.11 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: 142.13 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: 147.96 Epsilon: 0.149\n",
            "Solved at episode: 635 Avg Results: 196.47\n",
            "\n",
            "Training with learning_rate=0.0005, hidden_size=128\n",
            "Episode: 50 Avg Results: -226.83 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -117.52 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -93.48 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -84.12 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -59.92 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: -15.69 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: 43.11 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: 51.54 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: 105.16 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: 66.41 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: 135.70 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: 106.95 Epsilon: 0.149\n",
            "Episode: 650 Avg Results: 179.58 Epsilon: 0.128\n",
            "Episode: 700 Avg Results: 122.57 Epsilon: 0.110\n",
            "Solved at episode: 725 Avg Results: 195.12\n",
            "\n",
            "Training with learning_rate=0.0005, hidden_size=256\n",
            "Episode: 50 Avg Results: -200.37 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -134.67 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -92.20 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -69.78 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -65.46 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: 27.91 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: 68.56 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: 63.67 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: 72.07 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: 125.67 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: 150.52 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: 160.78 Epsilon: 0.149\n",
            "Episode: 650 Avg Results: 189.34 Epsilon: 0.128\n",
            "Solved at episode: 662 Avg Results: 198.46\n",
            "\n",
            "Training with learning_rate=0.001, hidden_size=64\n",
            "Episode: 50 Avg Results: -184.93 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -127.18 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -101.77 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -72.36 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -66.46 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: -33.48 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: 36.56 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: 9.54 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: 38.86 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: 98.58 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: 122.29 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: 87.14 Epsilon: 0.149\n",
            "Solved at episode: 622 Avg Results: 197.37\n",
            "\n",
            "Training with learning_rate=0.001, hidden_size=128\n",
            "Episode: 50 Avg Results: -182.09 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -125.64 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -70.28 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -52.93 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -3.99 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: 23.35 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: 10.86 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: 60.66 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: 66.70 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: 78.10 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: 140.42 Epsilon: 0.173\n",
            "Solved at episode: 598 Avg Results: 196.48\n",
            "\n",
            "Training with learning_rate=0.001, hidden_size=256\n",
            "Episode: 50 Avg Results: -185.76 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -116.88 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -81.11 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -67.78 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -17.96 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: -7.07 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: 9.21 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: 73.86 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: 89.67 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: 79.30 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: 121.44 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: 45.36 Epsilon: 0.149\n",
            "Episode: 650 Avg Results: 80.37 Epsilon: 0.128\n",
            "Solved at episode: 698 Avg Results: 195.63\n",
            "\n",
            "Training with learning_rate=0.01, hidden_size=64\n",
            "Episode: 50 Avg Results: -156.10 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -93.37 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -91.98 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -74.35 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -51.66 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: -59.17 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: -52.91 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: -67.60 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: -112.56 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: -52.58 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: -99.07 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: -22.14 Epsilon: 0.149\n",
            "Episode: 650 Avg Results: -87.10 Epsilon: 0.128\n",
            "Episode: 700 Avg Results: -81.32 Epsilon: 0.110\n",
            "Episode: 750 Avg Results: -134.74 Epsilon: 0.095\n",
            "Episode: 800 Avg Results: -77.67 Epsilon: 0.082\n",
            "Episode: 850 Avg Results: -83.13 Epsilon: 0.070\n",
            "Episode: 900 Avg Results: -28.09 Epsilon: 0.060\n",
            "Episode: 950 Avg Results: -144.92 Epsilon: 0.052\n",
            "Episode: 1000 Avg Results: -60.69 Epsilon: 0.050\n",
            "Episode: 1050 Avg Results: -57.05 Epsilon: 0.050\n",
            "Episode: 1100 Avg Results: -145.28 Epsilon: 0.050\n",
            "Episode: 1150 Avg Results: -43.73 Epsilon: 0.050\n",
            "Episode: 1200 Avg Results: 24.12 Epsilon: 0.050\n",
            "Episode: 1250 Avg Results: -32.67 Epsilon: 0.050\n",
            "Episode: 1300 Avg Results: -75.07 Epsilon: 0.050\n",
            "Episode: 1350 Avg Results: -74.10 Epsilon: 0.050\n",
            "Episode: 1400 Avg Results: -63.69 Epsilon: 0.050\n",
            "Episode: 1450 Avg Results: -66.56 Epsilon: 0.050\n",
            "Episode: 1500 Avg Results: -7.98 Epsilon: 0.050\n",
            "Episode: 1550 Avg Results: -17.86 Epsilon: 0.050\n",
            "Episode: 1600 Avg Results: -51.65 Epsilon: 0.050\n",
            "Episode: 1650 Avg Results: -58.40 Epsilon: 0.050\n",
            "Episode: 1700 Avg Results: -133.94 Epsilon: 0.050\n",
            "Episode: 1750 Avg Results: -91.92 Epsilon: 0.050\n",
            "Episode: 1800 Avg Results: -150.30 Epsilon: 0.050\n",
            "Episode: 1850 Avg Results: -34.30 Epsilon: 0.050\n",
            "Episode: 1900 Avg Results: -116.57 Epsilon: 0.050\n",
            "Episode: 1950 Avg Results: -93.80 Epsilon: 0.050\n",
            "Episode: 2000 Avg Results: -40.94 Epsilon: 0.050\n",
            "Did not solve within 2000 episodes. Final avg reward: -40.94\n",
            "\n",
            "Training with learning_rate=0.01, hidden_size=128\n",
            "Episode: 50 Avg Results: -139.94 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -86.61 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -57.40 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -76.95 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -54.10 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: -72.07 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: -79.12 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: -90.82 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: -104.78 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: -53.50 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: -130.19 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: -101.95 Epsilon: 0.149\n",
            "Episode: 650 Avg Results: -102.03 Epsilon: 0.128\n",
            "Episode: 700 Avg Results: -87.03 Epsilon: 0.110\n",
            "Episode: 750 Avg Results: -113.27 Epsilon: 0.095\n",
            "Episode: 800 Avg Results: -159.19 Epsilon: 0.082\n",
            "Episode: 850 Avg Results: -98.39 Epsilon: 0.070\n",
            "Episode: 900 Avg Results: -97.69 Epsilon: 0.060\n",
            "Episode: 950 Avg Results: -106.59 Epsilon: 0.052\n",
            "Episode: 1000 Avg Results: -102.55 Epsilon: 0.050\n",
            "Episode: 1050 Avg Results: -154.51 Epsilon: 0.050\n",
            "Episode: 1100 Avg Results: -86.51 Epsilon: 0.050\n",
            "Episode: 1150 Avg Results: -130.50 Epsilon: 0.050\n",
            "Episode: 1200 Avg Results: -101.63 Epsilon: 0.050\n",
            "Episode: 1250 Avg Results: -51.29 Epsilon: 0.050\n",
            "Episode: 1300 Avg Results: -50.49 Epsilon: 0.050\n",
            "Episode: 1350 Avg Results: -100.09 Epsilon: 0.050\n",
            "Episode: 1400 Avg Results: -127.93 Epsilon: 0.050\n",
            "Episode: 1450 Avg Results: -101.25 Epsilon: 0.050\n",
            "Episode: 1500 Avg Results: -105.41 Epsilon: 0.050\n",
            "Episode: 1550 Avg Results: -65.74 Epsilon: 0.050\n",
            "Episode: 1600 Avg Results: -22.89 Epsilon: 0.050\n",
            "Episode: 1650 Avg Results: -55.33 Epsilon: 0.050\n",
            "Episode: 1700 Avg Results: -23.81 Epsilon: 0.050\n",
            "Episode: 1750 Avg Results: -77.06 Epsilon: 0.050\n",
            "Episode: 1800 Avg Results: -42.34 Epsilon: 0.050\n",
            "Episode: 1850 Avg Results: -62.74 Epsilon: 0.050\n",
            "Episode: 1900 Avg Results: -66.00 Epsilon: 0.050\n",
            "Episode: 1950 Avg Results: -48.27 Epsilon: 0.050\n",
            "Episode: 2000 Avg Results: -59.90 Epsilon: 0.050\n",
            "Did not solve within 2000 episodes. Final avg reward: -59.90\n",
            "\n",
            "Training with learning_rate=0.01, hidden_size=256\n",
            "Episode: 50 Avg Results: -101.52 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -95.72 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -66.09 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -42.60 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -30.79 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: -70.90 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: -89.20 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: -130.56 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: -112.50 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: -116.53 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: -113.49 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: -144.92 Epsilon: 0.149\n",
            "Episode: 650 Avg Results: -139.82 Epsilon: 0.128\n",
            "Episode: 700 Avg Results: -107.63 Epsilon: 0.110\n",
            "Episode: 750 Avg Results: -107.92 Epsilon: 0.095\n",
            "Episode: 800 Avg Results: -115.70 Epsilon: 0.082\n",
            "Episode: 850 Avg Results: -146.81 Epsilon: 0.070\n",
            "Episode: 900 Avg Results: -162.44 Epsilon: 0.060\n",
            "Episode: 950 Avg Results: -127.34 Epsilon: 0.052\n",
            "Episode: 1000 Avg Results: -102.60 Epsilon: 0.050\n",
            "Episode: 1050 Avg Results: -104.51 Epsilon: 0.050\n",
            "Episode: 1100 Avg Results: -101.64 Epsilon: 0.050\n",
            "Episode: 1150 Avg Results: -150.43 Epsilon: 0.050\n",
            "Episode: 1200 Avg Results: -95.69 Epsilon: 0.050\n",
            "Episode: 1250 Avg Results: -141.52 Epsilon: 0.050\n",
            "Episode: 1300 Avg Results: -143.25 Epsilon: 0.050\n",
            "Episode: 1350 Avg Results: -64.55 Epsilon: 0.050\n",
            "Episode: 1400 Avg Results: -183.19 Epsilon: 0.050\n",
            "Episode: 1450 Avg Results: -145.22 Epsilon: 0.050\n",
            "Episode: 1500 Avg Results: -91.34 Epsilon: 0.050\n",
            "Episode: 1550 Avg Results: -99.62 Epsilon: 0.050\n",
            "Episode: 1600 Avg Results: -157.19 Epsilon: 0.050\n",
            "Episode: 1650 Avg Results: -85.24 Epsilon: 0.050\n",
            "Episode: 1700 Avg Results: -123.35 Epsilon: 0.050\n",
            "Episode: 1750 Avg Results: -177.55 Epsilon: 0.050\n",
            "Episode: 1800 Avg Results: -169.90 Epsilon: 0.050\n",
            "Episode: 1850 Avg Results: -110.53 Epsilon: 0.050\n",
            "Episode: 1900 Avg Results: -151.34 Epsilon: 0.050\n",
            "Episode: 1950 Avg Results: -127.11 Epsilon: 0.050\n",
            "Episode: 2000 Avg Results: -168.07 Epsilon: 0.050\n",
            "Did not solve within 2000 episodes. Final avg reward: -168.07\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 10000\n",
        "MIN_REPLAY_SIZE = 5000\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 0.997\n",
        "TARGET_UPDATE_FREQ = 5\n",
        "\n",
        "\n",
        "learning_rates = [0.0005, 0.001, 0.01]\n",
        "hidden_sizes = [64, 128, 256]\n",
        "\n",
        "Transition = namedtuple('Transition', ('states', 'actions', 'rewards', 'dones', 'next_states'))\n",
        "\n",
        "class Replay_memory():\n",
        "    def __init__(self, env, fullsize, minsize, batchsize):\n",
        "        self.env = env\n",
        "        self.memory = deque(maxlen=fullsize)\n",
        "        self.rewards = deque(maxlen=50)\n",
        "        self.batchsize = batchsize\n",
        "        self.minsize = minsize\n",
        "\n",
        "    def append(self, transition):\n",
        "        self.memory.append(transition)\n",
        "\n",
        "    def sample_batch(self):\n",
        "        batch = random.sample(self.memory, self.batchsize)\n",
        "        batch = Transition(*zip(*batch))\n",
        "        states = torch.from_numpy(np.array(batch.states, dtype=np.float32))\n",
        "        actions = torch.from_numpy(np.array(batch.actions, dtype=np.int64)).unsqueeze(1)\n",
        "        rewards = torch.from_numpy(np.array(batch.rewards, dtype=np.float32)).unsqueeze(1)\n",
        "        dones = torch.from_numpy(np.array(batch.dones, dtype=np.bool8)).unsqueeze(1)\n",
        "        next_states = torch.from_numpy(np.array(batch.next_states, dtype=np.float32))\n",
        "        return states, actions, rewards, dones, next_states\n",
        "\n",
        "    def initialize(self):\n",
        "        obs, info = self.env.reset()\n",
        "        for _ in range(self.minsize):\n",
        "            action = self.env.action_space.sample()\n",
        "            new_obs, reward, terminated, truncated, info = self.env.step(action)\n",
        "            done = terminated or truncated\n",
        "            transition = Transition(obs, action, reward, done, new_obs)\n",
        "            self.append(transition)\n",
        "            obs = new_obs\n",
        "            if done:\n",
        "                obs, info = self.env.reset()\n",
        "        return self\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, ninputs, noutputs, hidden_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.a1 = nn.Linear(ninputs, hidden_size)\n",
        "        self.a2 = nn.Linear(hidden_size, noutputs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        o = self.a1(X)\n",
        "        o = torch.tanh(o)\n",
        "        o = self.a2(o)\n",
        "        return o\n",
        "\n",
        "    def __call__(self, X):\n",
        "        return self.forward(X)\n",
        "\n",
        "def epsilon_greedy_policy(epsilon, obs, dqn_policy, env):\n",
        "    rnd_sample = random.random()\n",
        "    if rnd_sample <= epsilon:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            action = int(torch.argmax(dqn_policy(torch.Tensor(obs))))\n",
        "    return action\n",
        "\n",
        "env = gym.make(\"LunarLander-v3\")\n",
        "\n",
        "def train(learning_rate, hidden_size):\n",
        "    obs, info = env.reset()\n",
        "    eps_threshold = EPS_START\n",
        "    episode = 1\n",
        "    episode_reward = 0.0\n",
        "    all_rewards = []  \n",
        "\n",
        "    replay_memory = Replay_memory(env, BUFFER_SIZE, MIN_REPLAY_SIZE, BATCH_SIZE).initialize()\n",
        "\n",
        "    dqn_policy = DQN(env.observation_space.shape[0], env.action_space.n, hidden_size)\n",
        "    dqn_target = DQN(env.observation_space.shape[0], env.action_space.n, hidden_size)\n",
        "    dqn_target.load_state_dict(dqn_policy.state_dict())\n",
        "    dqn_target.eval()\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(dqn_policy.parameters(), lr=learning_rate)\n",
        "\n",
        "    for step in itertools.count():\n",
        "        action = epsilon_greedy_policy(eps_threshold, obs, dqn_policy, env)\n",
        "        new_obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        replay_memory.append(Transition(obs, action, reward, done, new_obs))\n",
        "        episode_reward += reward\n",
        "        obs = new_obs\n",
        "\n",
        "        if done:\n",
        "            episode += 1\n",
        "            eps_threshold = np.max((eps_threshold * EPS_DECAY, EPS_END))\n",
        "            replay_memory.rewards.append(episode_reward)\n",
        "            obs, info = env.reset()\n",
        "            avg_res = np.mean(replay_memory.rewards)\n",
        "            all_rewards.append(avg_res)\n",
        "\n",
        "            if episode % 50 == 0:\n",
        "                print(f'Episode: {episode} Avg Results: {avg_res:.2f} Epsilon: {eps_threshold:.3f}')\n",
        "\n",
        "            if len(replay_memory.rewards) == 50 and avg_res >= 195:\n",
        "                print(f'Solved at episode: {episode} Avg Results: {avg_res:.2f}')\n",
        "                break\n",
        "\n",
        "            if episode >= 2000:  \n",
        "                print(f'Did not solve within 2000 episodes. Final avg reward: {avg_res:.2f}')\n",
        "                break\n",
        "            episode_reward = 0\n",
        "\n",
        "        b_states, b_actions, b_rewards, b_dones, b_next_states = replay_memory.sample_batch()\n",
        "\n",
        "        qvalues = dqn_policy(b_states).gather(1, b_actions)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            target_qvalues = dqn_target(b_next_states)\n",
        "            max_target_qvalues = torch.max(target_qvalues, axis=1).values.unsqueeze(1)\n",
        "            expected_qvalues = b_rewards + GAMMA * (1 - b_dones.type(torch.int64)) * max_target_qvalues\n",
        "\n",
        "        loss = loss_fn(qvalues, expected_qvalues)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        for param in dqn_policy.parameters():\n",
        "            param.grad.data.clamp_(-1, 1)\n",
        "        optimizer.step()\n",
        "\n",
        "        if episode % TARGET_UPDATE_FREQ == 0:\n",
        "            dqn_target.load_state_dict(dqn_policy.state_dict())\n",
        "\n",
        "    return all_rewards, dqn_policy\n",
        "\n",
        "\n",
        "results = []\n",
        "models = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for hidden_size in hidden_sizes:\n",
        "        print(f\"\\nTraining with learning_rate={lr}, hidden_size={hidden_size}\")\n",
        "        all_rewards, model = train(lr, hidden_size)\n",
        "        \n",
        "        \n",
        "        solved_episode = None  \n",
        "        final_avg_reward = np.mean(all_rewards[-50:])  \n",
        "        \n",
        "        \n",
        "        for i in range(50, len(all_rewards)):\n",
        "            if np.mean(all_rewards[i-50:i]) >= 195:\n",
        "                solved_episode = i\n",
        "                break\n",
        "        \n",
        "        results.append({\n",
        "            'learning_rate': lr,\n",
        "            'hidden_size': hidden_size,\n",
        "            'episodes_to_solve': solved_episode if solved_episode else float('inf'),  \n",
        "            'avg_reward': final_avg_reward\n",
        "        })\n",
        "        models[(lr, hidden_size)] = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ehMcRQlTjm3"
      },
      "source": [
        "From these results, the hidden_size of 128 and learning rate of 0.001 needed the least amount of episodes to achieve the avrage result of 195 in the last 50 episodes (621 episodes). These values will now be used to continue this experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test episode reward for standard DQN: 132.79\n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_lr = 0.001\n",
        "best_hidden_size = 128\n",
        "best_model = models[(best_lr, best_hidden_size)]\n",
        "torch.save(best_model.state_dict(), 'standard_dqn.pth')\n",
        "\n",
        "\n",
        "standard_model = DQN(env.observation_space.shape[0], env.action_space.n, hidden_size=128)\n",
        "standard_model.load_state_dict(torch.load('standard_dqn.pth'))\n",
        "standard_model.eval()\n",
        "\n",
        "\n",
        "obs, _ = env.reset()\n",
        "total_reward = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    with torch.no_grad():\n",
        "        action = int(torch.argmax(standard_model(torch.Tensor(obs))))\n",
        "    obs, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"Test episode reward for standard DQN: {total_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luhjfWGYSN2P"
      },
      "source": [
        "## 2. Apply one improvement to the standard DQN (apply separately) and compare/discuss against the standard DQN. Compare the new model against the standard DQN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caP_FJUZSZqu"
      },
      "source": [
        "For this, I will use Double DQN as the DQN improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZOdZl3zVSm2K"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Sequence\n",
        "from collections import namedtuple, deque\n",
        "import itertools\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 10000\n",
        "MIN_REPLAY_SIZE = 5000\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 0.997\n",
        "TARGET_UPDATE_FREQ = 5\n",
        "learning_rate = 0.001  \n",
        "\n",
        "Transition = namedtuple('Transition', ('states', 'actions', 'rewards', 'dones', 'next_states'))\n",
        "\n",
        "class Replay_memory():\n",
        "    def __init__(self, env, fullsize, minsize, batchsize):\n",
        "        self.env = env\n",
        "        self.memory = deque(maxlen=fullsize)\n",
        "        self.rewards = deque(maxlen=50)\n",
        "        self.batchsize = batchsize\n",
        "        self.minsize = minsize\n",
        "\n",
        "    def append(self, transition):\n",
        "        self.memory.append(transition)\n",
        "\n",
        "    def sample_batch(self):\n",
        "        batch = random.sample(self.memory, self.batchsize)\n",
        "        batch = Transition(*zip(*batch))\n",
        "        states = torch.from_numpy(np.array(batch.states, dtype=np.float32))\n",
        "        actions = torch.from_numpy(np.array(batch.actions, dtype=np.int64)).unsqueeze(1)\n",
        "        rewards = torch.from_numpy(np.array(batch.rewards, dtype=np.float32)).unsqueeze(1)\n",
        "        dones = torch.from_numpy(np.array(batch.dones, dtype=np.bool8)).unsqueeze(1)\n",
        "        next_states = torch.from_numpy(np.array(batch.next_states, dtype=np.float32))\n",
        "        return states, actions, rewards, dones, next_states\n",
        "\n",
        "    def initialize(self):\n",
        "        obs, info = self.env.reset()\n",
        "        for _ in range(self.minsize):\n",
        "            action = self.env.action_space.sample()\n",
        "            new_obs, reward, terminated, truncated, info = self.env.step(action)\n",
        "            done = terminated or truncated\n",
        "            transition = Transition(obs, action, reward, done, new_obs)\n",
        "            self.append(transition)\n",
        "            obs = new_obs\n",
        "            if done:\n",
        "                obs, info = self.env.reset()\n",
        "        return self\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, ninputs, noutputs):\n",
        "        super(DQN, self).__init__()\n",
        "        self.a1 = nn.Linear(ninputs, 128)  \n",
        "        self.a2 = nn.Linear(128, noutputs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        o = self.a1(X)\n",
        "        o = torch.tanh(o)\n",
        "        o = self.a2(o)\n",
        "        return o\n",
        "\n",
        "    def __call__(self, X):\n",
        "        return self.forward(X)\n",
        "\n",
        "def epsilon_greedy_policy(epsilon, obs):\n",
        "    rnd_sample = random.random()\n",
        "    if rnd_sample <= epsilon:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            action = int(torch.argmax(dqn_policy(torch.Tensor(obs))))\n",
        "    return action\n",
        "\n",
        "\n",
        "env = gym.make(\"LunarLander-v3\")\n",
        "obs, info = env.reset()\n",
        "episode_reward = 0.0\n",
        "\n",
        "\n",
        "replay_memory = Replay_memory(env, BUFFER_SIZE, MIN_REPLAY_SIZE, BATCH_SIZE).initialize()\n",
        "\n",
        "\n",
        "dqn_policy = DQN(env.observation_space.shape[0], env.action_space.n)\n",
        "dqn_target = DQN(env.observation_space.shape[0], env.action_space.n)\n",
        "dqn_target.load_state_dict(dqn_policy.state_dict())\n",
        "dqn_target.eval()\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(dqn_policy.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "def train():\n",
        "    obs, info = env.reset()\n",
        "    eps_threshold = EPS_START\n",
        "    episode = 1\n",
        "    episode_reward = 0.0\n",
        "    all_rewards = []  \n",
        "\n",
        "    for step in itertools.count():\n",
        "        action = epsilon_greedy_policy(eps_threshold, obs)\n",
        "        new_obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        replay_memory.append(Transition(obs, action, reward, done, new_obs))\n",
        "        episode_reward += reward\n",
        "        obs = new_obs\n",
        "\n",
        "        if done:\n",
        "            episode += 1\n",
        "            eps_threshold = np.max((eps_threshold*EPS_DECAY, EPS_END))\n",
        "            replay_memory.rewards.append(episode_reward)\n",
        "            obs, info = env.reset()\n",
        "            avg_res = np.mean(replay_memory.rewards)\n",
        "            all_rewards.append(avg_res)\n",
        "\n",
        "            if episode % 50 == 0:\n",
        "                print(f'Episode: {episode} Avg Results: {avg_res:.2f} Epsilon: {eps_threshold:.3f}')\n",
        "\n",
        "            if len(replay_memory.rewards) == 50 and avg_res >= 195:\n",
        "                print(f'Solved at episode: {episode} Avg Results: {avg_res:.2f}')\n",
        "                break\n",
        "            episode_reward = 0\n",
        "\n",
        "        b_states, b_actions, b_rewards, b_dones, b_next_states = replay_memory.sample_batch()\n",
        "\n",
        "        qvalues = dqn_policy(b_states).gather(1, b_actions)\n",
        "\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            _, next_actions = dqn_policy(b_next_states).max(dim=1, keepdim=True)    \n",
        "            next_action_values = dqn_target(b_next_states).gather(1, next_actions)   \n",
        "            expected_qvalues = b_rewards + GAMMA * (1 - b_dones.type(torch.int64)) * next_action_values\n",
        "\n",
        "        loss = loss_fn(qvalues, expected_qvalues)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        for param in dqn_policy.parameters():\n",
        "            param.grad.data.clamp_(-1, 1)\n",
        "        optimizer.step()\n",
        "\n",
        "        if episode % TARGET_UPDATE_FREQ == 0:\n",
        "            dqn_target.load_state_dict(dqn_policy.state_dict())\n",
        "\n",
        "    return all_rewards, dqn_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-Ki22rC9S8hS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 50 Avg Results: -163.60 Epsilon: 0.777\n",
            "Episode: 100 Avg Results: -122.62 Epsilon: 0.668\n",
            "Episode: 150 Avg Results: -59.89 Epsilon: 0.575\n",
            "Episode: 200 Avg Results: -67.59 Epsilon: 0.495\n",
            "Episode: 250 Avg Results: -80.97 Epsilon: 0.426\n",
            "Episode: 300 Avg Results: -38.70 Epsilon: 0.367\n",
            "Episode: 350 Avg Results: 68.16 Epsilon: 0.315\n",
            "Episode: 400 Avg Results: 81.25 Epsilon: 0.271\n",
            "Episode: 450 Avg Results: 34.97 Epsilon: 0.234\n",
            "Episode: 500 Avg Results: 113.32 Epsilon: 0.201\n",
            "Episode: 550 Avg Results: 125.36 Epsilon: 0.173\n",
            "Episode: 600 Avg Results: 165.82 Epsilon: 0.149\n",
            "Episode: 650 Avg Results: 162.43 Epsilon: 0.128\n",
            "Solved at episode: 666 Avg Results: 200.05\n",
            "Test episode reward for Double DQN: 229.92\n"
          ]
        }
      ],
      "source": [
        "rewards, double_model = train()\n",
        "\n",
        "torch.save(double_model.state_dict(), 'double_dqn.pth')\n",
        "\n",
        "\n",
        "obs, _ = env.reset()\n",
        "total_reward = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    with torch.no_grad():\n",
        "        action = int(torch.argmax(double_model(torch.Tensor(obs))))\n",
        "    obs, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    total_reward += reward\n",
        "\n",
        "print(f\"Test episode reward for Double DQN: {total_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDURFmNhYfez"
      },
      "source": [
        "## 3. As a key objective for this experiment you are asked to investigate how varying degrees of noise (in the state), say HIGH-MEDIUM-LOW, impact the trained DQN models in different ways, providing deeper insights into model robustness. By comparing performance at multiple noise levels, explore how sensitive/resistant each of the two models is to increasing noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UTAY-sW_Zq5N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def inject_gaussian_noise(state, noise_level=0.1):\n",
        "  \"\"\"\n",
        "\n",
        "  Injects Gaussian noise into the given state tensor\n",
        "\n",
        "  Parameters:\n",
        "  - state (torch.Tensor): The original state tensor\n",
        "  - noise_level (float): The standard deviation of the Gaussian noise to inject.\n",
        "\n",
        "  Returns:\n",
        "  - torch.Tensor: The state tensor with added Gaussian Noise\n",
        "  \"\"\"\n",
        "  #Ensure state is a torch tensor\n",
        "  if not isinstance(state, torch.Tensor):\n",
        "    state = torch.tensor(state, dtype=torch.float32)\n",
        "\n",
        "  # Generate Gaussian noise and inject it into the state\n",
        "  noise = torch.randn(state.size()) * noise_level\n",
        "  noisy_state = state + noise\n",
        "  return noisy_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8Z13uh0GaYJ-"
      },
      "outputs": [],
      "source": [
        "NOISE_LEVELS = {\n",
        "    'LOW': 0.05,\n",
        "    'MEDIUM': 0.15,\n",
        "    'HIGH': 0.25\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sQ4-FNEybOty"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_with_noise(model, noise_level, num_episodes=100):\n",
        "    rewards = []\n",
        "    env = gym.make(\"LunarLander-v3\")\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        episode_reward = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            \n",
        "            noisy_obs = inject_gaussian_noise(obs, noise_level)\n",
        "\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                noisy_obs_tensor = torch.FloatTensor(noisy_obs)\n",
        "                action = int(torch.argmax(model(noisy_obs_tensor)))\n",
        "\n",
        "            \n",
        "            obs, reward, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            episode_reward += reward\n",
        "\n",
        "        rewards.append(episode_reward)\n",
        "\n",
        "    return np.mean(rewards), np.std(rewards)\n",
        "\n",
        "\n",
        "def compare_model_robustness(standard_dqn, double_dqn):\n",
        "    results = {\n",
        "        'standard': {},\n",
        "        'double': {}\n",
        "    }\n",
        "\n",
        "    for noise_name, noise_level in NOISE_LEVELS.items():\n",
        "        print(f\"\\nTesting with {noise_name} noise (σ={noise_level})\")\n",
        "\n",
        "        \n",
        "        std_mean, std_std = evaluate_model_with_noise(standard_dqn, noise_level)\n",
        "        results['standard'][noise_name] = (std_mean, std_std)\n",
        "        print(f\"Standard DQN - Mean reward: {std_mean:.2f} ± {std_std:.2f}\")\n",
        "\n",
        "        \n",
        "        dbl_mean, dbl_std = evaluate_model_with_noise(double_dqn, noise_level)\n",
        "        results['double'][noise_name] = (dbl_mean, dbl_std)\n",
        "        print(f\"Double DQN - Mean reward: {dbl_mean:.2f} ± {dbl_std:.2f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def plot_robustness_comparison(results):\n",
        "    noise_levels = list(NOISE_LEVELS.keys())\n",
        "    standard_means = [results['standard'][level][0] for level in noise_levels]\n",
        "    double_means = [results['double'][level][0] for level in noise_levels]\n",
        "    standard_stds = [results['standard'][level][1] for level in noise_levels]\n",
        "    double_stds = [results['double'][level][1] for level in noise_levels]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x = np.arange(len(noise_levels))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.bar(x - width/2, standard_means, width, label='Standard DQN', yerr=standard_stds, capsize=5)\n",
        "    plt.bar(x + width/2, double_means, width, label='Double DQN', yerr=double_stds, capsize=5)\n",
        "\n",
        "    plt.xlabel('Noise Level')\n",
        "    plt.ylabel('Average Reward')\n",
        "    plt.title('Model Performance Under Different Noise Levels')\n",
        "    plt.xticks(x, noise_levels)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VDgvJl1qbhds"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing with LOW noise (σ=0.05)\n",
            "Standard DQN - Mean reward: 146.10 ± 77.48\n",
            "Double DQN - Mean reward: 81.80 ± 114.83\n",
            "\n",
            "Testing with MEDIUM noise (σ=0.15)\n",
            "Standard DQN - Mean reward: 49.70 ± 68.59\n",
            "Double DQN - Mean reward: -22.45 ± 126.69\n",
            "\n",
            "Testing with HIGH noise (σ=0.25)\n",
            "Standard DQN - Mean reward: 11.06 ± 41.21\n",
            "Double DQN - Mean reward: -63.32 ± 116.09\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "env = gym.make(\"LunarLander-v3\")\n",
        "n_observations = env.observation_space.shape[0]\n",
        "n_actions = 4  \n",
        "\n",
        "\n",
        "standard_model = DQN(n_observations, n_actions, hidden_size=128)  \n",
        "standard_model.load_state_dict(torch.load('standard_dqn.pth'))\n",
        "standard_model.eval()\n",
        "\n",
        "double_model = DQN(n_observations, n_actions, hidden_size=128)  \n",
        "double_model.load_state_dict(torch.load('double_dqn.pth'))\n",
        "double_model.eval()\n",
        "\n",
        "\n",
        "results = compare_model_robustness(standard_model, double_model)\n",
        "\n",
        "\n",
        "plot_robustness_comparison(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
